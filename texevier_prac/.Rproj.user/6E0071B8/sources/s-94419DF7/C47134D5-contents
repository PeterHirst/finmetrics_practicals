---
title: 'Texevier practical submission: getting used to the environment for my research
  paper'
Author1: Peter Hirst
BottomRFooter: \footnotesize Page \thepage\
output:
  pdf_document:
    fig_height: 3.5
    fig_width: 3.5
    include:
      in_header: Tex/packages.txt
    keep_tex: no
    template: Tex/TexDefault.txt
  word_document: default
HardSet_layout: yes
Journal: Journal of Finance
Ref1: Stellenbosch University
RemovePreprintSubmittedTo: yes
abstract: |
  The purpose of this paper is to allow myself to become accustomed to the Texevier environment, to be able to successfully write my research paper. My research paper will study the effect of Fed rate hikes on the EME currencies, specifically BRICS economies.
addfootrule: yes
addtoprule: yes
bibliography: Tex/ref.bib
bottom: 2
documentclass: elsarticle
fontsize: 11pt
linenumbers: no
linestretch: 1.2
link-citations: yes
margin: 2.3
numbersections: yes
Email1: peterhirst01\@gmail.com
AddTitle: yes
toc: no
top: 2.5
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf. These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{introduction}
 This marks the beginning of my mini write-up, which serves as practice in working with Texevier. It consists of a couple of interesting calculations, tables and plots to get me to understand how to work in the Texevier environment. The layout of the rest of this paper is as follows: section \ref{returns} summarises the mean and variance for the stocks over two different periods. Section \ref{referencing} includes a brief exercise in referencing, to prove I am able to do this when it comes to my final project. I reference @Tsay1989 and @Texevier (the package in which is used to write this paper). Section \ref{correlations} tabulates the unconditional, full sample correlations between the stocks. Section \ref{garch} plots the univariate GARCH ht processes for each of the series in our sample. Section \ref{cum_returns} plots the cumulative returns of our portfolio of stocks, equally weighted and reweighted each year at the end of June. Section \ref{conclusion} concludes.
 
# Returns calculations \label{returns}
Below, I summarise the first and second moments of the returns of all the stocks in the portfolio, for three different periods.^[There is no data for the third period, so only two of them are summarised.] I do this using the _xtable_ package in R, which allows one to create slick tables.

Table \ref{tab1} shows the mean and variance (first and second moments) of the returns from 2006 to 2008 and table \ref{tab2} does so for 2010 to 2013.

```{r Table 1, results='asis'}
library(xtable)
library(psych)
library(rmsfuns)

load_pkg(c("tidyverse", "devtools", "rugarch", "forecast", "tbl2xts", 
    "lubridate", "PerformanceAnalytics", "ggthemes"))

dailydata <- read_csv("https://raw.githubusercontent.com/Nicktz/ExDat/master/extdata/findata.csv", 
    col_types = cols(.default = "d", Date = "D"))


# Change the column names to make it more readable
colnames(dailydata) <-
colnames(dailydata) %>% gsub("JSE.","",.) %>% gsub(".Close","",.)

#tidy it up
tidydata <- 
dailydata %>% 
  gather(key = Tickers, value = Scores, -Date)

#calculate returns
returns <- 
tidydata %>% 
  group_by(Tickers) %>% 
  mutate(Returns = Scores/lag(Scores) - 1) %>% 
  mutate(LogReturns = (log(Returns) - log(lag(Returns))))

# period 1
period1summary <- 
  returns %>%
  filter(Date >= ymd(20060518) & Date<= ymd(20081231)) %>% 
  group_by(Tickers) %>% 
  summarise(mean = mean(Returns, na.rm = T), variance = var(Returns, na.rm = T)) %>% 
  tbl_df()

table1 <-
  xtable(period1summary %>% mutate_at(vars(-Tickers), funs(paste0(round(.*100, 2), "%"))), caption = "Summary of the first and second moments of a portfolio of stocks: 2006-2008 \\label{tab1}")
  print.xtable(table1, 
             floating = TRUE, 
             table.placement = 'H',
             comment = FALSE, 
             caption.placement = 'bottom'
            )

# period 2
period2summary <- 
  returns %>%
  filter(Date >= ymd(20100101) & Date<= ymd(20131231)) %>% 
  group_by(Tickers) %>% 
  summarise(mean = mean(Returns, na.rm = T), variance = var(Returns, na.rm = T)) %>% 
  tbl_df()

table2 <-
  xtable(period2summary %>% mutate_at(vars(-Tickers), funs(paste0(round(.*100, 2), "%"))), caption = "Summary of the first and second moments of a portfolio of stocks: 2010-2013 \\label{tab2}")
  print.xtable(table2, 
             floating = TRUE, 
             table.placement = 'H',
             comment = FALSE, 
             caption.placement = 'bottom'
            )

```

The negative mean returns in the first period (for two of the stocks) is immediately evident. It could be that the financial crisis had an adverse effect on business operations during this time, which reflected in the company returns. The variance is also higher during this period suggesting higher stock market volatility. For the second period, the returns are positive across all stocks and the variance seems lower, overall.


# Referencing \label{referencing}
The purpose of this section is to show that I am able to reference in R Markdown. For this reason, I added the Tsay textbook which I saved in my ref.bib file. It discusses the _Testing and modeling threshold autoregressive processes_ [@Tsay1989]. Or we could include a page number in the following way @Tsay1989[p 35]. Let us try referencing two sources together: this paper makes use of both Tsay and Katzke's work, with Tsay's work discussing the analysis of AR processes as well as a package, which is used in RStudio (published in CRAN) [@Tsay1989 \& @Texevier].

How about referencing an author and page number wrapped around in brackets? @Tsay1989 states that "AR1 processes are persistent processes that can best be explained by including an AR1 term and an error term" [@Tsay1989 p 56].

# Unconditional (full sample) correlations between the stocks \label{correlations}
This section aims to calculate the full sample correlations between the stocks in our portfolio. Naturally, the diagonal entries will all equal unity^[By defintion, the correlation between the stock and itself is one.], whereas the off-diagonals give us a sense of the coveriance between the stocks in our portfolio. See table \ref{table_corr} below for the correlation matrix.
```{r Table2, results='asis'}
# Here, I generate a table with the full sample correlations of all the stocks in the sample.

print.xtable(xtable(cor(dailydata[, c(2:8)], use = "complete.obs"),
                    caption = "Full sample correlations between stocks \\label{table_corr}"),
             floating = T,
             table.placement = 'H',
             scalebox = "0.7",
             comment = F,
             caption.placement = 'bottom'
)
```


# Univariate GARCH processes \label{garch}
This section plots the univariate GARCH ht processes for each of the series in our sample. Please see figure \ref{fig1}, which plots the GARCH processes.

```{r GARCH_fig, warning =  FALSE, fig.align = 'center', fig.cap = "GARCH ht processes of the stocks in our sample \\label{fig1}", fig.ext = 'png'}
if (!require("rugarch")) install.packages("rugarch")
library(rugarch)

cl = makePSOCKcluster(10)

# Make the data wide
wide_returns <- returns %>% 
  select(-c(Scores, LogReturns)) %>% 
  spread(Tickers, Returns) %>% tbl_xts()
#make the portfolio
porteqw = Return.portfolio(wide_returns, weight = NULL, geometric = FALSE)

AC = autoarfima(as.numeric(porteqw), ar.max = 2, ma.max = 2, 
                criterion = "AIC", method = "partial", arfima = FALSE, include.mean = NULL, 
                distribution.model = "norm", solver = "solnp", cluster = cl)

#Specify the GARCH model
garch11 <-
ugarchspec(
variance.model = list(model = c("sGARCH","gjrGARCH","eGARCH","fGARCH","apARCH")[1],
garchOrder = c(2, 2)),
mean.model = list(armaOrder = c(1, 0), include.mean = TRUE),
distribution.model = c("norm", "snorm", "std", "sstd", "ged", "sged", "nig", "ghyp", "jsu")[1])

garchfit1 = ugarchfit(spec = garch11, data = as.numeric(porteqw))


  

```

```{r garch, results='hide', fig.keep='all', warning =  FALSE, fig.align = 'center', fig.cap = "GARCH ht processes of the stocks in our sample \\label{fig1}", fig.ext = 'png'}
plot(garchfit1, which = "all")

```

# Cumulative returns \label{cum_returns}
This section deals with "cumulative returns calculations". The aim is to plot the cumulative returns series of a portfolio that is equally weighted to each of the stocks.^[The portfolio is reweighted each year at the end of June.] Let us get straight to it. Figure \ref{fig2} plots the cumulative returns for an equally-weighted portfolio of stocks.
```{r cum_returns_fig, warning =  FALSE, fig.align = 'center', fig.cap = "Cumulative returns of a portfolio of equally-weighted stocks \\label{fig2}", fig.ext = 'png', fig.height = 3, fig.width = 6}

if (!require("rportfolios")) install.packages("rportfolios")
library(rportfolios)
library(ggthemes)

# Drop the unnecessary
returns$LogReturns <- NULL
returns$Scores <- NULL
#Create a group of tickers, in this case all of them that will be used in the portfolio
# This is not necessary seeing as we are using all the Tickers

# Rebalancing
RebMonths <- c(6)

# Create the weights vector 
Weights <-
returns %>% 
  mutate(Months = as.double(format(Date, format = "%m")), YearMonths = as.double(format(Date, format = "%Y%m"))) %>% 
  filter(Months %in% RebMonths) %>% 
  group_by(YearMonths, Months, Tickers) %>% 
  filter(Date == last(Date)) %>%
  ungroup()

# Now we have to add the actual weights to the vector at each rebalancing 
Weights_adj <- 
  Weights %>% 
  group_by(Date) %>% 
  mutate(EqualWeights = 1/n()) %>% 
  ungroup() %>% 
  select(-Months, -YearMonths)

# Next task is to create a portfollio 
library(PerformanceAnalytics)

Fund_Size_at_Start <- 1000

# Remember when using PA, the data must be xts and wide
# Create the equal weights to feed into the function later on
EW_weights <- Weights_adj %>% 
  select(Date, Tickers, EqualWeights) %>%
  spread(Tickers, EqualWeights) %>% tbl_xts()

# Isolate the returns
df_Returns <- returns %>% spread(Tickers, Returns)
df_Returns[is.na(df_Returns)] <- 0 # this sets the NA values to zero
xts_df_Returns <- df_Returns %>% tbl_xts() # basically, here we just get the returns in xts format

# Create the equally weighted portfolio
EW_RetPort <- Return.portfolio(xts_df_Returns, weights = EW_weights,
verbose = TRUE, contribution = TRUE, value = Fund_Size_at_Start,
geometric = TRUE)

# Clean and save portfolio returns and weights:
EW_Contribution <- 
  EW_RetPort$contribution %>% 
  xts_tbl() %>%
  mutate(date = lag(date), date = coalesce(date, index(EW_weights)[1]))

EW_BPWeight <- 
  EW_RetPort$BOP.Weight %>% 
  xts_tbl() %>% 
  mutate(date = lag(date),
  date = coalesce(date, index(EW_weights)[1]))

EW_BPValue <- 
  EW_RetPort$BOP.Value %>% 
  xts_tbl() %>% 
  mutate(date = lag(date),
  date = coalesce(date, index(EW_weights)[1]))

# Names
names(EW_Contribution) <- c("date", names(EW_RetPort$contribution))
names(EW_BPWeight) <- c("date", names(EW_RetPort$BOP.Weight))
names(EW_BPValue) <- c("date", names(EW_RetPort$BOP.Value))

# Bind  everything together
df_port_return_EW <- 
  left_join(returns %>% 
              rename(date = Date),
EW_BPWeight %>% 
  gather(Tickers, weight, -date), by = c("date",
  "Tickers")) %>% left_join(., EW_BPValue %>% gather(Tickers,
  value_held, -date), by = c("date", "Tickers")) %>% 
  left_join(.,
EW_Contribution %>% 
  gather(Tickers, Contribution, -date),
  by = c("date", "Tickers"))

# Portfolio return
df_Portf_EW <- df_port_return_EW %>% group_by(date) %>% summarise(PortfolioReturn = sum(Returns *
weight, na.rm = TRUE)) %>% filter(PortfolioReturn != 0)

# Portfolio cumulative return
Cum_EW <- 
  df_Portf_EW %>% 
  mutate(cumreturn_EW = (cumprod(1 +
  PortfolioReturn) - 1)) %>% 
  mutate(wealthindex_EW = 100 *
  (cumprod(1 + PortfolioReturn))) %>% select(-PortfolioReturn)

# Now we can go ahead and plot the wealth index (i.e. if you invested R100 yesterday, how much would you have now?)
Cum_EW %>%
  ggplot() +
  geom_line(aes(date, wealthindex_EW, color = "wealth index")) +
  theme_bw() + labs(x = "Date", y = "Growth")

# This will then plot the cumulative returns for portfolio, which is exactly what we are looking for.
```


# Conclusion \label{conclusion}
This mini write-up proves that I am able to produce an academic paper using the Texevier package, developed by @Texevier. The paper conducted a few calculations on financial time series of seven stocks. Returns-calculations were conducted to plot the cumulative returns, correlations were tabulated and GARCH processes were run. Essentially, the purpose was to express all findings in a professional template, which was succseefully completed.

## Subtitle
This is just me practising how to create a subsection.

### Subsubtitle
This is just me practising how to create a subsubsection.

# References

```{r, include=FALSE}
#this is how to cite Texevier as a package.
citation("Texevier")
```










